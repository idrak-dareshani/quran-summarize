"""
Test script to verify all dependencies are installed correctly
"""

def test_imports():
    """Test if all required packages can be imported."""
    
    test_results = {}
    
    # Test core packages
    try:
        import torch
        test_results['torch'] = f"âœ… PyTorch {torch.__version__}"
    except ImportError as e:
        test_results['torch'] = f"âŒ PyTorch: {e}"
    
    try:
        import whisper
        test_results['whisper'] = "âœ… OpenAI Whisper"
    except ImportError as e:
        test_results['whisper'] = f"âŒ Whisper: {e}"
    
    try:
        import transformers
        test_results['transformers'] = f"âœ… Transformers {transformers.__version__}"
    except ImportError as e:
        test_results['transformers'] = f"âŒ Transformers: {e}"
    
    # Test optional packages
    try:
        import librosa
        test_results['librosa'] = f"âœ… Librosa {librosa.__version__}"
    except ImportError as e:
        test_results['librosa'] = f"âš ï¸ Librosa (optional): {e}"
    
    try:
        import soundfile
        test_results['soundfile'] = f"âœ… SoundFile {soundfile.__version__}"
    except ImportError as e:
        test_results['soundfile'] = f"âš ï¸ SoundFile (optional): {e}"
    
    return test_results

def test_whisper_models():
    """Test if Whisper models can be loaded."""
    try:
        import whisper
        
        print("ğŸ“‹ Available Whisper models:")
        for model_name in whisper.available_models():
            print(f"   - {model_name}")
        
        # Test loading a small model
        print("\nğŸ”„ Testing model loading (this may take a moment)...")
        model = whisper.load_model("tiny")
        print("âœ… Whisper model loaded successfully!")
        
        return True
    except Exception as e:
        print(f"âŒ Error loading Whisper model: {e}")
        return False

def test_gpu_availability():
    """Check if GPU is available for processing."""
    try:
        import torch
        if torch.cuda.is_available():
            gpu_count = torch.cuda.device_count()
            gpu_name = torch.cuda.get_device_name(0)
            print(f"ğŸš€ GPU Available: {gpu_name} (Count: {gpu_count})")
            return True
        else:
            print("ğŸ’» Using CPU (GPU not available)")
            return False
    except Exception as e:
        print(f"âŒ Error checking GPU: {e}")
        return False

def main():
    """Run all tests."""
    print("ğŸ” Testing Audio Processing Pipeline Installation\n")
    
    # Test imports
    print("1ï¸âƒ£ Testing Package Imports:")
    results = test_imports()
    for package, status in results.items():
        print(f"   {status}")
    
    print("\n" + "="*50 + "\n")
    
    # Test GPU
    print("2ï¸âƒ£ Testing GPU Availability:")
    test_gpu_availability()
    
    print("\n" + "="*50 + "\n")
    
    # Test Whisper
    print("3ï¸âƒ£ Testing Whisper Models:")
    whisper_ok = test_whisper_models()
    
    print("\n" + "="*50 + "\n")
    
    # Summary
    failed_imports = [pkg for pkg, status in results.items() if "âŒ" in status]
    
    if not failed_imports and whisper_ok:
        print("ğŸ‰ All tests passed! Your installation is ready.")
        print("\nğŸ“ Next steps:")
        print("   1. Place your audio file in the 'audio/' directory")
        print("   2. Run: python main.py")
    else:
        print("âš ï¸ Some issues found:")
        if failed_imports:
            print(f"   - Failed imports: {', '.join(failed_imports)}")
        if not whisper_ok:
            print("   - Whisper model loading failed")
        print("\nğŸ”§ Please install missing dependencies and try again.")

if __name__ == "__main__":
    main()